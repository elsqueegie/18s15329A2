{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmacdonald/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/jmacdonald/anaconda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t37882\n",
      "- Validation-set:\t6262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 24 00:21:41 2018\n",
    "\n",
    "@author: aditya.sharma\n",
    "\"\"\"\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "\n",
    "# ### *Step 1:* Loading data\n",
    "# The MNIST data-set is about 12 MB and will be downloaded automatically if it is not located in the given path.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self, images, labels, img_names, cls):\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._img_names = img_names\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_done = 0\n",
    "        self._cls = cls\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def img_names(self):\n",
    "        return self._img_names\n",
    "\n",
    "    @property\n",
    "    def cls(self):\n",
    "        return self._cls\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
    "    \n",
    "\n",
    "def load_data(input_path, dataset_type, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_names = []\n",
    "    cls = []\n",
    "    \n",
    "    data_path = os.path.join(input_path, str(dataset_type+'-set'))\n",
    "    label_path = os.path.join(input_path, str(dataset_type+'.txt'))\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        lines = label_file.readlines()\n",
    "        random.shuffle(lines)\n",
    "        for line in lines:\n",
    "            filename, index = line.split(' ')\n",
    "            label = np.zeros(62)\n",
    "            label[int(index)] = 1.0\n",
    "            labels.append(label)\n",
    "            \n",
    "            \n",
    "            img_names.append(filename)\n",
    "            image_file_path = os.path.join(data_path, filename)\n",
    "            image = cv2.imread(image_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            image = np.reshape(image, image_size*image_size)\n",
    "            images.append(image)\n",
    "            cls.append(int(index))\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    img_names = np.array(img_names)\n",
    "    cls = np.array(cls)\n",
    "\n",
    "            \n",
    "    return DataSet(images, labels, img_names, cls)\n",
    "            \n",
    "\n",
    "def read_train_sets(input_path, image_size):\n",
    "    class DataSets(object):\n",
    "        pass\n",
    "    data_sets = DataSets()\n",
    "    \n",
    "    data_sets.train = load_data(input_path, 'train', image_size)\n",
    "    data_sets.validation = load_data(input_path, 'vali', image_size)\n",
    "    \n",
    "    return data_sets\n",
    "    \n",
    " \n",
    "# In[3]: load data\n",
    "\n",
    "input_path = '../Input/'\n",
    "validation_size = 0.2\n",
    "img_size = 32\n",
    "num_channels = 1\n",
    "num_classes = 62\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = read_train_sets(input_path, img_size)\n",
    "\n",
    "# The MNIST data-set has now been loaded and consists of 70,000 images and associated labels (i.e. classifications of the images). The data-set is split into 3 mutually exclusive sub-sets. We will only use the training and validation-sets in this tutorial.\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "#print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))\n",
    "\n",
    "\n",
    "# The class-labels are One-Hot encoded, which means that each label is a vector with 10 elements, all of which are zero except for one element. The index of this one element is the class-number, that is, the digit shown in the associated image. We also need the class-numbers as integers for the validation-set, so we calculate it now.\n",
    "\n",
    "# ### Helper-function for plotting images - MNIST\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def plot_images(images, cls_true, img_shape=None, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape((img_size,img_size)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "images = data.validation.images[0:9]\n",
    "cls_true = data.validation.cls[0:9]\n",
    "\n",
    "plot_images(images=images, cls_true=cls_true)\n",
    "\n",
    "\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1\n",
    "num_classes = 62\n",
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataSet at 0x7f0534b826a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-81666bcf76e3>:356: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exp 3 : 10000 iterations val accuracy:22.5\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "stride_size1 = 1\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 32         # There are 36 of these filters.\n",
    "stride_size2 = 1\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters3 = 64         # There are 36 of these filters.\n",
    "stride_size3 = 1\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size4 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters4 = 128         # There are 36 of these filters.\n",
    "stride_size4 = 1\n",
    "\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 500             # Number of neurons in fully-connected layer.\n",
    "dropout = 0.1\n",
    "\n",
    "regularization_coefficient = 0.01\n",
    "\n",
    "\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "\n",
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   stride_size,        # Stride over x- and y- channel\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    strides =[1, stride_size, stride_size, 1]\n",
    "    \n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=strides,\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "# #### Function for flattening a layer\n",
    "# \n",
    "# A convolutional layer produces an output tensor with 4 dimensions. We will add fully-connected layers after the \n",
    "# convolution layers, so we need to reduce the 4-dim tensor to 2-dim which can be used as input to the fully-connected \n",
    "# layer.\n",
    "\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "# #### Function for creating a new Fully-Connected Layer\n",
    "\n",
    "# This function creates a new fully-connected layer in the computational graph for TensorFlow. Nothing is actually \n",
    "# calculated here, we are just adding the mathematical formulas to the TensorFlow graph.\n",
    "# \n",
    "# It is assumed that the input is a 2-dim tensor of shape `[num_images, num_inputs]`. The output is a 2-dim tensor of \n",
    "# shape `[num_images, num_outputs]`.\n",
    "\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True,\n",
    "                 dropout=0.05\n",
    "                ): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "    layer = tf.nn.dropout(layer, 1-dropout)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "# #### Placeholder variables\n",
    "\n",
    "# Placeholder variables serve as the input to the TensorFlow computational graph that we may change each time we \n",
    "# execute the graph. We call this feeding the placeholder variables and it is demonstrated further below.\n",
    "# \n",
    "# First we define the placeholder variable for the input images. This allows us to change the images that are input to \n",
    "# the TensorFlow graph. This is a so-called tensor, which just means that it is a multi-dimensional vector or matrix. \n",
    "# The data-type is set to `float32` and the shape is set to `[None, img_size_flat]`, where `None` means that the \n",
    "# tensor may hold an arbitrary number of images with each image being a vector of length `img_size_flat`.\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "\n",
    "\n",
    "# The convolutional layers expect `x` to be encoded as a 4-dim tensor so we have to reshape it so its shape is instead \n",
    "# `[num_images, img_height, img_width, num_channels]`. Note that `img_height == img_width == img_size` and `num_images`\n",
    "# can be inferred automatically by using -1 for the size of the first dimension. So the reshape operation is:\n",
    "\n",
    "\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "\n",
    "# Next we have the placeholder variable for the true labels associated with the images that were input in the \n",
    "# placeholder variable `x`. The shape of this placeholder variable is `[None, num_classes]` which means it may hold an \n",
    "# arbitrary number of labels and each label is a vector of length `num_classes` which is 10 in this case.\n",
    "\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "\n",
    "\n",
    "# We could also have a placeholder variable for the class-number, but we will instead calculate it using argmax. \n",
    "# Note that this is a TensorFlow operator so nothing is calculated at this point.\n",
    "\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "\n",
    "\n",
    "# ### Convolutional Layer 1\n",
    "# \n",
    "# Create the first convolutional layer. It takes `x_image` as input and creates `num_filters1` different filters, \n",
    "# each having width and height equal to `filter_size1`. Finally we wish to down-sample the image so it is half the \n",
    "# size by using 2x2 max-pooling.\n",
    "\n",
    "\n",
    "layer_conv1, weights_conv1 =     new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   stride_size=stride_size1,\n",
    "                   use_pooling=False)\n",
    "\n",
    "layer_conv2, weights_conv2 =     new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   stride_size=stride_size2,\n",
    "                   use_pooling=True)\n",
    "\n",
    "layer_conv3, weights_conv3 =     new_conv_layer(input=layer_conv2,\n",
    "                   num_input_channels=num_filters2,\n",
    "                   filter_size=filter_size3,\n",
    "                   num_filters=num_filters3,\n",
    "                   stride_size=stride_size3,\n",
    "                   use_pooling=False)\n",
    "\n",
    "layer_conv4, weights_conv4 =     new_conv_layer(input=layer_conv3,\n",
    "                   num_input_channels=num_filters3,\n",
    "                   filter_size=filter_size4,\n",
    "                   num_filters=num_filters4,\n",
    "                   stride_size=stride_size4,\n",
    "                   use_pooling=True)\n",
    "\n",
    "\n",
    "# Check the shape of the tensor that will be output from this convolutional layer. The shape is (?, 7, 7, 36) \n",
    "# where the ? again means that there is an arbitrary number of images, with each image having width and height of 7 \n",
    "# pixels, and there are 36 channels, one for each filter.\n",
    "\n",
    "\n",
    "layer_conv2\n",
    "\n",
    "\n",
    "# ### Flatten Layer\n",
    "# \n",
    "# The convolutional layers output 4-dim tensors. We now wish to use these as input in a fully-connected network, \n",
    "# which requires for the tensors to be reshaped or flattened to 2-dim tensors.\n",
    "\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer_conv4)\n",
    "\n",
    "\n",
    "# Check that the tensors now have shape (?, 1764) which means there's an arbitrary number of images which have been \n",
    "# flattened to vectors of length 1764 each. Note that 1764 = 7 x 7 x 36.\n",
    "\n",
    "\n",
    "# ### Fully-Connected Layer 1\n",
    "# \n",
    "# Add a fully-connected layer to the network. The input is the flattened layer from the previous convolution. \n",
    "# The number of neurons or nodes in the fully-connected layer is `fc_size`. ReLU is used so we can learn non-linear \n",
    "# relations.\n",
    "\n",
    "\n",
    "layer_fc1, fc1_weights = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "\n",
    "# Check that the output of the fully-connected layer is a tensor with shape (?, 128) where the ? means there is an \n",
    "# arbitrary number of images and `fc_size` == 128.\n",
    "\n",
    "# ### Fully-Connected Layer 2\n",
    "# \n",
    "# Add another fully-connected layer that outputs vectors of length 10 for determining which of the 10 classes the \n",
    "# input image belongs to. Note that ReLU is not used in this layer.\n",
    "\n",
    "\n",
    "layer_fc2, fc2_weights = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "\n",
    "\n",
    "# ### Predicted Class\n",
    "\n",
    "# The second fully-connected layer estimates how likely it is that the input image belongs to each of the 10 classes. \n",
    "# However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, \n",
    "# so we want to normalize them so that each element is limited between zero and one and the 10 elements sum to one. \n",
    "# This is calculated using the so-called softmax function and the result is stored in `y_pred`.\n",
    "\n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "\n",
    "# ### Cost-function to be optimized\n",
    "\n",
    "# To make the model better at classifying the input images, we must somehow change the variables for all the network \n",
    "# layers. To do this we first need to know how well the model currently performs by comparing the predicted output of \n",
    "# the model `y_pred` to the desired output `y_true`.\n",
    "# \n",
    "# The cross-entropy is a performance measure used in classification. The cross-entropy is a continuous function that \n",
    "# is always positive and if the predicted output of the model exactly matches the desired output then the cross-entropy\n",
    "# equals zero. The goal of optimization is therefore to minimize the cross-entropy so it gets as close to zero as \n",
    "# possible by changing the variables of the network layers.\n",
    "# \n",
    "# TensorFlow has a built-in function for calculating the cross-entropy. Note that the function calculates the softmax \n",
    "# internally so we must use the output of `layer_fc2` directly rather than `y_pred` which has already had the softmax \n",
    "# applied.\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)\n",
    "\n",
    "\n",
    "# We have now calculated the cross-entropy for each of the image classifications so we have a measure of how well the \n",
    "# model performs on each image individually. But in order to use the cross-entropy to guide the optimization of the \n",
    "# model's variables we need a single scalar value, so we simply take the average of the cross-entropy for all the \n",
    "# image classifications.\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "regularizers = tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc2_weights)\n",
    "cost = tf.reduce_mean(cost + regularization_coefficient * regularizers)\n",
    "\n",
    "\n",
    "# ### Optimization Method\n",
    "\n",
    "# Now that we have a cost measure that must be minimized, we can then create an optimizer. In this case it is the \n",
    "# `AdamOptimizer` which is an advanced form of Gradient Descent.\n",
    "# \n",
    "# Note that optimization is not performed at this point. In fact, nothing is calculated at all, we just add the \n",
    "# optimizer-object to the TensorFlow graph for later execution.\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "\n",
    "# ### Performance Measures\n",
    "\n",
    "# We need a few more performance measures to display the progress to the user.\n",
    "# \n",
    "# This is a vector of booleans whether the predicted class equals the true class of each image.\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "\n",
    "# This calculates the classification accuracy by first type-casting the vector of booleans to floats, \n",
    "# so that False becomes 0 and True becomes 1, and then calculating the average of these numbers.\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "train_scores = []\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "    global train_scores\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch, _, _ = data.train.next_batch(train_batch_size)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            train_scores.append(acc)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "# Split the validation-set into smaller batches of this size.\n",
    "validation_batch_size = 256\n",
    "\n",
    "def print_validation_accuracy():\n",
    "\n",
    "    # Number of images in the validation-set.\n",
    "    num_validation = len(data.validation.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_validation, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_validation:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + validation_batch_size, num_validation)\n",
    "\n",
    "        # Get the images from the validation-set between index i and j.\n",
    "        images = data.validation.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.validation.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the validation-set.\n",
    "    cls_true = data.validation.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the validation-set.\n",
    "    acc = float(correct_sum) / num_validation\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on validation-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   0.0%\n",
      "Optimization Iteration:    101, Training Accuracy:  18.8%\n",
      "Optimization Iteration:    201, Training Accuracy:  39.1%\n",
      "Optimization Iteration:    301, Training Accuracy:  42.2%\n",
      "Optimization Iteration:    401, Training Accuracy:  54.7%\n",
      "Time usage: 0:05:33\n",
      "Accuracy on validation-Set: 58.8% (3683 / 6262)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# ## Performance after 10,000 optimization iterations\n",
    "# \n",
    "# After 10,000 optimization iterations, the model has a classification accuracy on the validation-set of about 99%.\n",
    "\n",
    "# In[ ]:\n",
    "optimize(num_iterations=500) # We performed 1000 iterations above.\n",
    "\n",
    "print_validation_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
