{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmacdonald/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/jmacdonald/anaconda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t37882\n",
      "- Validation-set:\t6262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 24 00:21:41 2018\n",
    "\n",
    "@author: aditya.sharma\n",
    "\"\"\"\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "\n",
    "# ### *Step 1:* Loading data\n",
    "# The MNIST data-set is about 12 MB and will be downloaded automatically if it is not located in the given path.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self, images, labels, img_names, cls):\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._img_names = img_names\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_done = 0\n",
    "        self._cls = cls\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def img_names(self):\n",
    "        return self._img_names\n",
    "\n",
    "    @property\n",
    "    def cls(self):\n",
    "        return self._cls\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
    "    \n",
    "\n",
    "def load_data(input_path, dataset_type, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_names = []\n",
    "    cls = []\n",
    "    \n",
    "    data_path = os.path.join(input_path, str(dataset_type+'-set'))\n",
    "    label_path = os.path.join(input_path, str(dataset_type+'.txt'))\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        lines = label_file.readlines()\n",
    "        random.shuffle(lines)\n",
    "        for line in lines:\n",
    "            filename, index = line.split(' ')\n",
    "            label = np.zeros(62)\n",
    "            label[int(index)] = 1.0\n",
    "            labels.append(label)\n",
    "            \n",
    "            \n",
    "            img_names.append(filename)\n",
    "            image_file_path = os.path.join(data_path, filename)\n",
    "            image = cv2.imread(image_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            image = np.reshape(image, image_size*image_size)\n",
    "            images.append(image)\n",
    "            cls.append(int(index))\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    img_names = np.array(img_names)\n",
    "    cls = np.array(cls)\n",
    "\n",
    "            \n",
    "    return DataSet(images, labels, img_names, cls)\n",
    "            \n",
    "\n",
    "def read_train_sets(input_path, image_size):\n",
    "    class DataSets(object):\n",
    "        pass\n",
    "    data_sets = DataSets()\n",
    "    \n",
    "    data_sets.train = load_data(input_path, 'train', image_size)\n",
    "    data_sets.validation = load_data(input_path, 'vali', image_size)\n",
    "    \n",
    "    return data_sets\n",
    "    \n",
    " \n",
    "# In[3]: load data\n",
    "\n",
    "input_path = '../Input/'\n",
    "validation_size = 0.2\n",
    "img_size = 32\n",
    "num_channels = 1\n",
    "num_classes = 62\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = read_train_sets(input_path, img_size)\n",
    "\n",
    "# The MNIST data-set has now been loaded and consists of 70,000 images and associated labels (i.e. classifications of \n",
    "# the images). The data-set is split into 3 mutually exclusive sub-sets. We will only use the training and \n",
    "# validation-sets in this tutorial.\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "#print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))\n",
    "\n",
    "\n",
    "# The class-labels are One-Hot encoded, which means that each label is a vector with 10 elements, all of which are \n",
    "# zero except for one element. The index of this one element is the class-number, that is, the digit shown in the \n",
    "# associated image. We also need the class-numbers as integers for the validation-set, so we calculate it now.\n",
    "\n",
    "# ### Helper-function for plotting images - MNIST\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def plot_images(images, cls_true, img_shape=None, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape((img_size,img_size)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "images = data.validation.images[0:9]\n",
    "cls_true = data.validation.cls[0:9]\n",
    "\n",
    "plot_images(images=images, cls_true=cls_true)\n",
    "\n",
    "\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1\n",
    "num_classes = 62\n",
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dictionary = {'relu':tf.nn.relu,'lrelu':tf.nn.leaky_relu,'tanh':tf.nn.tanh,'sigmoid':tf.nn.sigmoid}\n",
    "\n",
    "def new_weights(shape):\n",
    "    new_weight = tf.truncated_normal(shape, stddev=0.05)\n",
    "    return tf.Variable(new_weight)\n",
    "\n",
    "def new_biases(length):\n",
    "    new_bias = tf.constant(0.05, shape=[length])\n",
    "    return tf.Variable(new_bias)\n",
    "\n",
    "def new_conv_layer(previous_layer,param_dic):\n",
    "    p = param_dic\n",
    "    weights = new_weights(shape=[p['fSize'], p['fSize'], p['channels'], p['fN']])\n",
    "    biases = new_biases(length=p['fN'])\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=previous_layer,\n",
    "                         filter=weights,\n",
    "                         strides=[1, p['sSize'], p['sSize'], 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "    \n",
    "    activation = activation_dictionary[p['activation']]\n",
    "    output = activation(layer)\n",
    "    return output, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "def new_fc_layer(input, num_inputs, num_outputs, use_relu=True, dropout=0.05): \n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.dropout(layer, 1-dropout)\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "# Set parameters for CNN layers\n",
    "\n",
    "convolution_params = {\n",
    "    'layer_1a':{'fSize':3, 'fN':16, 'sSize':1, 'activation':'relu', 'channels':1},\n",
    "    'layer_1b':{'fSize':5, 'fN':16, 'sSize':1, 'activation':'relu', 'channels':1},\n",
    "    'layer_1c':{'fSize':7, 'fN':16, 'sSize':1, 'activation':'relu', 'channels':1},\n",
    "    \n",
    "    'layer_2a':{'fSize':3, 'fN':32, 'sSize':1, 'activation':'relu', 'channels':48},\n",
    "    'layer_2b':{'fSize':5, 'fN':32, 'sSize':1, 'activation':'relu', 'channels':48},\n",
    "    'layer_2c':{'fSize':7, 'fN':32, 'sSize':1, 'activation':'relu', 'channels':48},\n",
    "    \n",
    "    'layer_3':{'fSize':5, 'fN':128, 'sSize':1, 'activation':'relu', 'channels':96},\n",
    "    \n",
    "    'layer_4':{'fSize':5, 'fN':256, 'sSize':1, 'activation':'relu', 'channels':128}\n",
    "}\n",
    "\n",
    "fc_params = {\n",
    "    'layer_1':{'nodes':500,'dropout':0.1},\n",
    "    'layer_2':{'nodes':500,'dropout':0.1}\n",
    "}\n",
    "\n",
    "regularization_coefficient = 0.01\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='label')\n",
    "y_true_class = tf.argmax(y_true, axis=1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, 1])\n",
    "\n",
    "p = convolution_params['layer_1a']\n",
    "layer_conv1a, weights_conv1 = new_conv_layer(previous_layer=x_image, param_dic=p)\n",
    "p = convolution_params['layer_1b']\n",
    "layer_conv1b, weights_conv1 = new_conv_layer(previous_layer=x_image, param_dic=p)\n",
    "p = convolution_params['layer_1c']\n",
    "layer_conv1c, weights_conv1 = new_conv_layer(previous_layer=x_image, param_dic=p)\n",
    "layer_conv1 = tf.concat([layer_conv1a,layer_conv1b,layer_conv1c], 3)\n",
    "\n",
    "p = convolution_params['layer_2a']\n",
    "layer_conv2a, weights_conv2 = new_conv_layer(previous_layer=layer_conv1, param_dic=p) \n",
    "p = convolution_params['layer_2b']\n",
    "layer_conv2b, weights_conv2 = new_conv_layer(previous_layer=layer_conv1, param_dic=p) \n",
    "p = convolution_params['layer_2c']\n",
    "layer_conv2c, weights_conv2 = new_conv_layer(previous_layer=layer_conv1, param_dic=p) \n",
    "layer_conv2 = tf.concat([layer_conv2a,layer_conv2b,layer_conv2c], 3)\n",
    "\n",
    "p = convolution_params['layer_3']\n",
    "layer_conv3, weights_conv3 = new_conv_layer(previous_layer=layer_conv2, param_dic=p) \n",
    "\n",
    "p = convolution_params['layer_4']\n",
    "layer_conv4, weights_conv4 = new_conv_layer(previous_layer=layer_conv3, param_dic=p)\n",
    "\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer_conv4)\n",
    "\n",
    "p = fc_params['layer_1']\n",
    "layer_fc1, fc1_weights = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=p['nodes'],\n",
    "                         use_relu=True)\n",
    "\n",
    "p = fc_params['layer_2']\n",
    "layer_fc2, fc2_weights = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=p['nodes'],\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "\n",
    "y_hat = tf.nn.softmax(layer_fc2)\n",
    "y_hat_class = tf.argmax(y_hat, axis=1)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "regularizers = tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc2_weights)\n",
    "cost = tf.reduce_mean(cost + regularization_coefficient * regularizers)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_hat_class, y_true_class)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "train_scores = []\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "    global train_scores\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch, _, _ = data.train.next_batch(train_batch_size)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            train_scores.append(acc)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "# Split the validation-set into smaller batches of this size.\n",
    "validation_batch_size = 256\n",
    "\n",
    "def print_validation_accuracy():\n",
    "\n",
    "    # Number of images in the validation-set.\n",
    "    num_validation = len(data.validation.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_validation, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_validation:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + validation_batch_size, num_validation)\n",
    "\n",
    "        # Get the images from the validation-set between index i and j.\n",
    "        images = data.validation.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.validation.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_hat_class, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the validation-set.\n",
    "    cls_true = data.validation.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the validation-set.\n",
    "    acc = float(correct_sum) / num_validation\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on validation-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   0.0%\n",
      "Optimization Iteration:    101, Training Accuracy:  21.9%\n",
      "Optimization Iteration:    201, Training Accuracy:  35.9%\n",
      "Optimization Iteration:    301, Training Accuracy:  35.9%\n",
      "Optimization Iteration:    401, Training Accuracy:  45.3%\n",
      "Optimization Iteration:    501, Training Accuracy:  48.4%\n",
      "Time usage: 0:05:39\n",
      "Accuracy on validation-Set: 45.7% (2863 / 6262)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# ## Performance after 10,000 optimization iterations\n",
    "# \n",
    "# After 10,000 optimization iterations, the model has a classification accuracy on the validation-set of about 99%.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "optimize(num_iterations=501) # We performed 1000 iterations above.\n",
    "\n",
    "print_validation_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=1501) # We performed 1000 iterations above.\n",
    "\n",
    "print_validation_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
