{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t37882\n",
      "- Validation-set:\t6262\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGMJJREFUeJzt3X+sFeWdx/H3lyq1apErXYSqRRCLJVqgsmjSpP6IP+ra\niqioxCgW0nZbMGrTraZxt+Amjf0dsI1NWxEoombt1Us1K0Vt6xa7IMWrqwhkEUpFsIpcLHVrRb77\nx52Rw71zzplzzjwzw72fV0LuOTPPmec5PHee+53neeYZc3dERPq7AUUXQESkDNQYioigxlBEBFBj\nKCICqDEUEQHUGIqIAGoMRUQANYYiIoAaQxERAA5pJLGZ9bvbVdzdii5DnlTHfZ/qOJkiQxER1BiK\niABqDEVEADWGIiKAGkMREUCNoYgIoMZQRARocJ5hK8444wwAfv/73yfuNws31StpNe+2tjYAurq6\nguUryTo6OgC4+OKL39sWsv6lHBYtWgTAtddem7i/6N8BRYYiIuQYGc6dOzdx+9q1a4PlOXLkyKr7\nFBGK5KtaRLhp06acS5Ist8bwnHPOSdz+rW99K1ie06dPT9y+Z8+eYHmKSG+DBg2qum/GjBk5lqQ6\nXSaLiJBjZHjIIclZLV++PFieX/rSlxK333fffcHyFJHe7rjjjqr7nnzyyRxLUp0iQxERcogMx4wZ\nU3P/7t27g+U9dOjQxO3f+973guUpIr0lDZ6EHDxthiJDERFyiAxvuummxO07d+4MnXVV69evLyxv\nkf7k6KOPrrpv5syZOZakPkWGIiLkEBlefvnlidvvvffeYHlOmzYtcXvSbXkiEs6CBQuq7uvs7Myx\nJPUpMhQRIYfIcMiQIYnbQ47o3nzzzYnbH3nkkWB5ikhvkydP7rWtbKPIMUWGIiIEjAxr3YsIsGXL\nllBZM27cuMTt3/nOd4LlKSL7NTOKPGzYMAC++MUvHrC92iIvWVNkKCJCwMjwoosuSty+d+/eUFnW\nVZZ7IEX6ulqjyM8880xDx/roRz8KwNVXX91SmepRZCgiQsDIcM6cOYnbly1bFirL9x4tICLFShpF\nbtb999+f2bFqUWQoIkLAyDC+zu8p5MrWt9xyS+L2devWBctTRParNYrcU3z1eMkllwAwfvz4xHQh\nryYr5ba4a2z16tXBjl1t0CavoXmR/u7BBx+suq/a0+9uvfXWxO15L+aiy2QREQJFhmeffXaIw9ZV\nxKMFRGS/T33qU4nbH3/88aqfqXbeXnrppZmUKS1FhiIiBIoMkwYyfve734XICij20QIiUv8cnDVr\nVq9t9QZT875JQpGhiAiBIsOzzjqr17aOjo4QWQHw9a9/PXH7pk2bguUpIvv95Cc/qbl/w4YNvbZ9\n7WtfS0xb1HmryFBEhECR4cCBA3ttC3n9n/QYQoAZM2YEy1Oad9hhhxVdBMlYI6PI9Zb3K+q8VWQo\nIkKOd6C89tprmR+z2iKuMS3ZVU71Rh7l4FGvLpMeCHfHHXfU/ExR560iQxERcowMTz31VAA2b96c\n2THXrFmTuH3JkiWZ5SHZGzFixAHv9QjXg9fixYtr7u/q6uq1rVoff9GzPxQZiogQKDLcu3dvr/sN\n7777bqD6o0MbEUeE1e5pvOaaa1rOQ7JXbRTxiSeeyLkkkpVJkyYlbm9vb++1rd4oclL/Yp4UGYqI\nANZIf42ZpUq8aNGiqv0CS5cuBZp7uEvc/3DUUUcl7o9HtjZu3Njwsatx9+RF2PqotHXcjB07dgBw\nzDHHHLB9+PDh7+0rguq4cRMnTgTg6aefTtzf1tYGHNhn+MILLwAwduzYauVqtVhVpaljRYYiIgSK\nDCH9CGE8urxo0aIDtn/oQx8CYPbs2XWPcf755wOwYsWKtMVLTVFDfQ899BCw/17TODI/4YQTgP33\npfa8M2nbtm0AHHfccc0VNiOq48Z1dnYC9ef6prF27VoATjvttJaPVY0iQxGRlIJFhsOGDQNg+/bt\njZcqpcGDBwNh1ytU1FDfs88+C8DHP/7xVOnj37kBA8rxt1h13Lgs54YOHz4cIGi/cZo6DjbpOv5i\ncafowoULAZg+fXrDx9q3bx8An/jEJ4D9J58cXOLL6SlTphRcEmlWPHDSivh8jqfZJU3MLkI5/jSL\niBQs2GVyX6FLqL5Pddz3aQBFRCQlNYYiIqgxFBEB1BiKiABqDEVEADWGIiKAGkMREaDxO1BeB/4Y\noiAlNaJ+kj5Hddz3qY4TNDTpWkSkr9JlsogIagxFRIAAq9aY2RDg8ejtMOBdIH6C/CR3/3uAPI8A\nfg0MjP7d5+63RftOBO4FjgZWA9Pd/Z2sy9CfFFHHUb6LgH8Ctrn7+IrtE4A7gSOAl4Cr3X1PiDL0\nFyU8j58CDo+SHgOsdPdMnyAVtM/QzOYAe9z9uz22W5T3vozyGQB8wN3/amaHAr8H/tnd15hZO7DU\n3R8ws58Bq9z9p1nkK/nVcXTMM4H/A37SozF8Bpjt7ivN7AvAcHefm1W+/V0ZzuMe6TqA+919aRb5\nxnK7TDaz0Wa2zszuAV4Ajjezror9V0WNFWZ2jJm1m9kaM1ttZmfUOra773P3v0ZvBwKHAm5m7wM+\nBTwY7VsEXJLxV5NIyDoGcPffAm8k7DrR3VdGr1cAl7X+bSRJEedxj/wH031Od2T4tYD8+wxPBn7g\n7mOBbTXSzQe+7e4TgSuA+D/3dDP7cdIHzGygmXUCrwIPu/sfgH8AXnf3d6NkLwPHZvNVpIpgdVzD\nejP7TPR6KnB8g5+XxuR9Hle6FFhe0WhmJthK11Vs6hnyVnEuMKbi0YFtZvYBd18FrEr6QNSHMd7M\n2oAHzexjwK4sCi0NCVbHNVwHzDOzuXRHDOoTDivX89jdX6xIMg34YQtlryrvxrCyNd8HVC64eFjF\na6PJTlp332VmTwIXAHcAHzKz90XR4XHU/ksmrQtexz25+zrgPAAzGwt8utVjSk15n8cvQvdlNzAB\n+M+GS5xCYVNrok7XXWZ2UtRxWvlgjMeAWfEbMxvf8/OVzGyomR0VvT6c7r9I66MG8L8qjj2dAH0N\nkizLOq7FzIZGPwcAtwKNXmZLk/I4jyuSTAU6Qs1WKHqe4c3AcuApuvvzYrOAT5rZc2a2Dvg81Oxr\n+DDwWzN7lu7pM4+4+6PRvn8Bbjaz/wWOBBYG+SZSTVZ1jJn9B91/3Maa2ctmdl206xoz20D3ibMZ\n+HmQbyLV5HEeA1xF9zS5IHQ7nogIxUeGIiKloMZQRAQ1hiIigBpDERFAjaGICNDgpGsz63dDz+5u\n9VP1Harjvk91nEyRoYgIagxFRAA1hiIigBpDERFAjaGICKDGUEQECLie4dFHHw3Azp07Q2XRtIrF\nJiVDW7ZsAWDEiHTPZY/Tbd26teHfl7feeguAY4/tXri8q6urVnLJWWdnJwDjxo1r+LNFnZ+KDEVE\nCBgZXnDBBaEO3bRXXnml6CJIgmHDhrF9+/aGPnP44d1PjVyzpnv1+dGjR2deLmleMxFhe3t7gJKk\nF6wxvPHGG0MdumlF/2dLskYbwkqXX57po3OlRRMnTmz6szNnzsywJI3TZbKICA2udN3IPY1lXEH7\nYx/7GADr16+vk3I/3beaXqMDKH/6058AOP745p/smUVnu+o4O2UdONG9ySIiKQXrM2y2lU8TUQ4e\nPBiA3bt3N5WHlEMrEeHjjz+eYUkkKwfjwElMkaGICPk/RD4Tigj7vjlz5tR8P2vWLKQ8zj777KY/\nW/QockyRoYgIAUeTGzVy5EgAXnrppapp9uzZA8AHP/jBUMXoRSON6TU6mlzpc5/7HAALFy6sme6E\nE044IK8sqI5bt3XrVqCxfuC47RkwIHxMptFkEZGUStNneOWVV9ZNs2zZshxKInl744036kaEsSwj\nQslOMzMD7rrrrgAlaZ4iQxERShQZxn1GtcybNy+HkkjepkyZUnQRpEmtjCJ/9atfzbAkrVNkKCJC\niUaT05SjiEUfNdKYXrOjyUUvtqs6bl7ZR5Er8tRosohIGqXpMxSRg09fGEWOKTIUEaEEkWGalXG1\nXL9IubQyA6Bso8ixwhvD66+/vm6asizxI9nau3dv0UWQJv30pz9t+DP79u0DyrvQii6TRUQoQWR4\n0UUX1U3zox/9KIeSSN7+9re/FV0EadKQIUMa/szcuXMDlCQ7igxFRChBZJjmL0wjD3CSg4ciw4NP\nKwMnt912W4YlyZ4iQxERShAZSv/1l7/8pegiSIOaGUWG/SPJZabIUESEAiPDCy+8MFW6tWvXBi6J\niKTVzCgylH8kGRQZiogABUaGN954Y6p0CxYsCFwSEamn1QV4yz6SDIoMRUSAAhd3feeddwA45JDa\nwWlbWxtdXV1ZZdswLfyZXqOLu27evBmAUaNGNZtlJlTH9b399tsADBw4MPPyNKu9vZ3LLrssVVot\n7ioiklJhfYb1IsJYkVGhiHQrU0QYmzlzZqbHU2QoIkIBkeGgQYNSpdNadyLFu+mmm4ouQlVZXzUq\nMhQRoYDIMM36hQCPPvpo4JKISD2333570UXoZcmSJUGOq8hQRIQCIsO0d57Mnz8/cElEpJ4yjiLP\nnj07yHFzbwwnTZqUKt2KFSsCl0REainb4El8g0ioB0rpMllEhAJvxztY6Fat9OIukKOOOipV+nhq\nxLx585rNMhOq475Pt+OJiKSkyLAORQ19n+q471NkKCKSkhpDERHUGIqIAGoMRUQANYYiIkDjd6C8\nDvwxREFKKt369X2L6rjvUx0naGhqjYhIX6XLZBER1BiKiABqDEVEgACNoZkNMbPO6N8OM9tW8T7I\n4mhmNsLMfmNm68zsBTObXbFvgpn9t5n9j5l1mNmRIcrQnxRRx1G+L0f12Glmqyq2f9PMnjOzZ81s\nuZkNC1WG/qKE5/GV0fZ9ZjY+SP4hB1DMbA6wx92/22O7RXnvyyifDwND3b3TzAYBzwAXuvtGM3sG\nmO3uK83sC8Bwd5+bRb6SXx1Hx3wZOMXdu3psH+Tub0avvwKMcvcwK4D2QyU5j8cCe4EFdJ/PnVnk\nWSm3y2QzGx217PcALwDHm1lXxf6rzOxn0etjzKzdzNaY2WozO6PWsd39lfg/Jzop1gPHRrtPdPeV\n0esVwGUZfzWJhKzjWuKGMHI4oCkSgRR1Hrv7OnffGOp7Qf59hicDP3D3scC2GunmA99294nAFUD8\nn3u6mf24VgZmNgo4BXg62rTezD4TvZ4KHN9C+aW+kHXswBNm9gczO+AJ4mZ2exQ5XgHMafE7SG1F\nnMfB5b3s/yZ3X5Mi3bnAmO4oHIA2M/uAu68CVlX7UBRa/wK43t33RJuvA+aZ2VygA3in2cJLKiHr\n+Ax33xb1Ca4wsxfd/SkAd78FuMXM/hX4MvDvrX0NqaGI8zi4vBvDv1a83gdUrjF2WMVrAya5+9/T\nHjjq1G0H7nb3ZfF2d18HnBelGQt8uolyS3rB6tjdt0U/d5hZBzAJeKpHsnvo/j1QYxhO7udxHgqb\nWhN1uu4ys5PMbAAwpWL3Y8Cs+E290aOoI3ch0Onu83vsGxr9HADcCtQMzyU7GdfxkfFMADM7gu4/\ncM9H70+qSDqZ7r4myUFe53Eeip5neDOwnO6/7i9XbJ8FfDKaLrEO+DzU7Gs4E5gGnFcx/H9BtO8a\nM9tA9wmyGfh5oO8iybKq4+HASjN7FlgNPOjuj0X7vmNmz5vZc8BZwFfCfBWpIvh5bGZToz7hfwSW\nm9kjWX8J3ZssIkLxkaGISCmoMRQRQY2hiAigxlBEBGhwnqHpeat9nuq471MdJ1NkKCKCGkMREUCN\noYgIoMZQRARQYygiAqgxFBEB1BiKiAD5r2f4nt/85jcAnHnmmZkfu2IxSQlkwoQJrF27trD8zz//\nfABWrFhRWBmkb1FkKCJCgZGhSCt+9atfAfD8888DcOqppxZZnD7pG9/4RsvH2Lx5MwCLFy8Omt/c\nua0/8LI0jeGvf/1rAM455xwAtmzZAsCIESN6pY0vg8eNGwdAZ2fmTw2Ug8Qpp5wCwPe//30AvvIV\nrevaqjlz5gDZNIYTJkyom2bMmDEH5NuITZs2Adk0hrpMFhGhwZWus7zBu+cAyuDBgwHYvXs3kC4y\njPX8DlkOoOgm/mS1BlDeffddAA45pPULj4ceegiAyZMnp0rfTN2rjg/0zjvdD5DMov7S1Ed8ZRdf\n6TUibj+efPLJmum0UIOISEql6TOMI8Jm/PnPfwZg6NChWRVHSuKSSy4B4OqrrwZgyZIlNdN/9rOf\nBeCXv/xl2IL1YYceeuh7r6dNmwbA0qVLE9PG2+P6acb48ckPzet5xZc2CmyWIkMREQqMDG+//XYA\nnnjiiZaPNX36dAAmTZrU8rGknO655x4AFi5cCFTvz7rhhhsARYZZ2bFjR839H/nIRzLPM+6zjD38\n8MNAuIgwpshQRIQCI8NHH330gJ9lOZaU28qVK4Hqt3HGsxIkG6+88krN/ccee2xmecUzTOKo/623\n3gL29wOHpshQRIQSjSaLSPls37695v7jjjuu5TzOPfdcoHe0f8QRR7R87EYoMhQRQZGhHGTqLfm2\nYcOGnErSP7z55ps192dxl0rPZdiKmhWiyFBEBEWGcpCoN98tdttttwUuiVRqZR2AnvMJH3jgAQCe\nfvrplsrULEWGIiIoMpQABgzo/hvbynp4ja5tF89JU59h+VWbTzh16tSiigQoMhQRARQZSgBxP1Iz\nKxc3K+85adK4sswnrEaNoRyU4mdrjBo1quCSSFplmUJTjS6TRURQZCgHGUWExXj77bcBeP/739/U\n5yun0RQ9haYaRYYiIigylACaeSDUySefDMCLL75YM93IkSMB2LVrFwBtbW3NFFEaFE96T3pAG+yv\nlzhyj61atQro/l0oyxSaahQZioigyFBKYv369cD+aTlr1qwB4LTTTktMHy/iOmPGDAAWLFgQuoj9\n2quvvgpUjwzjpbziyDB+QFTliHFZptBUo8hQRARFhlJSEydOBPaPYg4cODAx3V133QUoMgwtjviq\nzQ0cPnw4AIMGDQJ6P9K1bHMKkygyFBFBkaGUXBxRdHZ21kwXP7Jy69atwcvUH9VbQi3u240f6Ror\n65zCJIoMRUQAc/f0ic3SJ27Rli1bgOTRq1YWlGyUu+eXWQmkreMJEyawdu3axH3NzDOsp97v6aZN\nmwAYPXp0M8dWHdcxZcoUANrb21Ol7+rqAsozDzRNHSsyFBFBfYZykOjo6ABg8uTJiftPPPHEPIvT\n79R7ZGhPZYkIG6HIUEQERYZykIjvNNm5c2fNdBdffDEAy5YtC16m/iS+F7yeMWPGBC5JOIoMRURQ\nZCgHiTfeeCNVuqVLlwJw5JFHhixOv1PvQVt33nknABs3bsyjOEEoMhQRoYSR4bBhw4Dqq2MA3HDD\nDQDMmzcvlzJJeSxevBiAa6+9NnF/2VdG6Wvi+YRf/vKXCy5J60o36brWZOue8ph8rQm5yfKedB2L\nFwLYvXt3zXTXXXcdixYtSnVM1XHfp0nXIiIplS4yLBtFDX2f6rjvU2QoIpKSGkMREdQYiogAagxF\nRAA1hiIigBpDERFAjaGICND47XivA38MUZCSqn8bTN+jOu77VMcJGpp0LSLSV+kyWUQENYYiIkCA\nJbzMbAjwePR2GPAu8Fr0fpK7/z1AniOARcBQwIE73f2H0b4JwJ3AEcBLwNXuvifrMvQnJazjB4D4\nGaFtwGvuPjHrMvQnRdRxlO/LwK4ov7fd/fRoe/A6DtpnaGZzgD3u/t0e2y3Ke19G+XwYGOrunWY2\nCHgGuNDdN5rZM8Bsd19pZl8Ahrv73CzylXLUcY9084BX3f2bWeQr+dVxdMyXgVPcvatGmiB1nNtl\nspmNNrN1ZnYP8AJwvJl1Vey/ysx+Fr0+xszazWyNma02szNqHdvdX3H3zuj1m8B64Nho94nuvjJ6\nvQK4LOOvJpEC6zg+/gBgKnBftt9MYiHrOGX+weo47z7Dk4EfuPtYYFuNdPOBb0dh8BVA/J97upn9\nuFYGZjYKOAV4Otq03sw+E72eChzfQvmlviLqOHYWsNXdX2qy7JJOyDp24Akz+4OZzUzYfxaB6jjv\nZf83ufuaFOnOBcZUrGTdZmYfcPdVwKpqH4oun34BXF/RL3gdMM/M5gIdwDvNFl5SKaKOY9OAe5so\nszQmZB2f4e7bzGwYsMLMXnT3pyr2B6vjvBvDv1a83gdULrh4WMVro8FOWjMbCLQDd7v7ew/Ndfd1\nwHlRmrHAp5sot6SXex1H+w4FLgH+reESS6OC1bG7b4t+7jCzDmAS8BSEr+PCptZEna67zOykqB9g\nSsXux4BZ8RszG1/rWFFH7kKg093n99g3NPo5ALgVqHkJJtnJq44jFwDPufv2lgsuqWVcx0ea2ZHR\n6yPoDmKer0gStI6Lnmd4M7Cc7pb/5Yrts4BPmtlzZrYO+DzU7Gs4k+7w+Twz64z+XRDtu8bMNtDd\n4b4Z+Hmg7yLJ8qhjgKvQJXJRsqrj4cBKM3sWWA086O6PVewPWse6HU9EhOIjQxGRUlBjKCKCGkMR\nEUCNoYgIoMZQRARQYygiAqgxFBEB1BiKiADw/+HmYFX5cSJ3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f521a4f55c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 24 00:21:41 2018\n",
    "\n",
    "@author: aditya.sharma\n",
    "\"\"\"\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "\n",
    "# ### *Step 1:* Loading data\n",
    "# The MNIST data-set is about 12 MB and will be downloaded automatically if it is not located in the given path.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self, images, labels, img_names, cls):\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._img_names = img_names\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_done = 0\n",
    "        self._cls = cls\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def img_names(self):\n",
    "        return self._img_names\n",
    "\n",
    "    @property\n",
    "    def cls(self):\n",
    "        return self._cls\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]\n",
    "    \n",
    "\n",
    "def load_data(input_path, dataset_type, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_names = []\n",
    "    cls = []\n",
    "    \n",
    "    data_path = os.path.join(input_path, str(dataset_type+'-set'))\n",
    "    label_path = os.path.join(input_path, str(dataset_type+'.txt'))\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        lines = label_file.readlines()\n",
    "        random.shuffle(lines)\n",
    "        for line in lines:\n",
    "            filename, index = line.split(' ')\n",
    "            label = np.zeros(62)\n",
    "            label[int(index)] = 1.0\n",
    "            labels.append(label)\n",
    "            \n",
    "            \n",
    "            img_names.append(filename)\n",
    "            image_file_path = os.path.join(data_path, filename)\n",
    "            image = cv2.imread(image_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            image = np.reshape(image, image_size*image_size)\n",
    "            images.append(image)\n",
    "            cls.append(int(index))\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    img_names = np.array(img_names)\n",
    "    cls = np.array(cls)\n",
    "\n",
    "            \n",
    "    return DataSet(images, labels, img_names, cls)\n",
    "            \n",
    "\n",
    "def read_train_sets(input_path, image_size):\n",
    "    class DataSets(object):\n",
    "        pass\n",
    "    data_sets = DataSets()\n",
    "    \n",
    "    data_sets.train = load_data(input_path, 'train', image_size)\n",
    "    data_sets.validation = load_data(input_path, 'vali', image_size)\n",
    "    \n",
    "    return data_sets\n",
    "    \n",
    " \n",
    "# In[3]: load data\n",
    "\n",
    "input_path = '../Input/'\n",
    "validation_size = 0.2\n",
    "img_size = 32\n",
    "num_channels = 1\n",
    "num_classes = 62\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = read_train_sets(input_path, img_size)\n",
    "\n",
    "# The MNIST data-set has now been loaded and consists of 70,000 images and associated labels (i.e. classifications of \n",
    "# the images). The data-set is split into 3 mutually exclusive sub-sets. We will only use the training and \n",
    "# validation-sets in this tutorial.\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "#print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))\n",
    "\n",
    "\n",
    "# The class-labels are One-Hot encoded, which means that each label is a vector with 10 elements, all of which are \n",
    "# zero except for one element. The index of this one element is the class-number, that is, the digit shown in the \n",
    "# associated image. We also need the class-numbers as integers for the validation-set, so we calculate it now.\n",
    "\n",
    "# ### Helper-function for plotting images - MNIST\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def plot_images(images, cls_true, img_shape=None, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape((img_size,img_size)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "images = data.validation.images[0:9]\n",
    "cls_true = data.validation.cls[0:9]\n",
    "\n",
    "plot_images(images=images, cls_true=cls_true)\n",
    "\n",
    "\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1\n",
    "num_classes = 62\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.contrib.layers.convolution2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(previous_layer,param_dic):\n",
    "    p = param_dic\n",
    "    weights = new_weights(shape=[p['fSize'], p['fSize'], p['channels'], p['fN']])\n",
    "    biases = new_biases(length=p['fN'])\n",
    "    layer = tf.nn.conv2d(input=previous_layer,\n",
    "                         filter=weights,\n",
    "                         strides=[1, p['sSize'], p['sSize'], 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "    \n",
    "    activation = activation_dictionary[p['activation']]\n",
    "    output = activation(layer)\n",
    "    return output, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-5d330136e7b7>:122: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activation_dictionary = {'relu':tf.nn.relu,'lrelu':tf.nn.leaky_relu,'tanh':tf.nn.tanh,'sigmoid':tf.nn.sigmoid}\n",
    "\n",
    "def new_weights(shape):\n",
    "    new_weight = tf.truncated_normal(shape, stddev=0.05)\n",
    "    return tf.Variable(new_weight)\n",
    "\n",
    "def new_biases(length):\n",
    "    new_bias = tf.constant(0.05, shape=[length])\n",
    "    return tf.Variable(new_bias)\n",
    "\n",
    "def new_conv_layer(previous_layer,param_dic):\n",
    "    p = param_dic\n",
    "    weights = new_weights(shape=[p['fSize'], p['fSize'], p['channels'], p['fN']])\n",
    "    biases = new_biases(length=p['fN'])\n",
    "    activation = activation_dictionary[p['activation']]\n",
    "    \n",
    "    layer = tf.contrib.layers.convolution2d(inputs=previous_layer,\n",
    "                                            num_outputs=p['fN'],\n",
    "                                            normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                            activation_fn=activation,\n",
    "                                            kernel_size=[p['fSize'],p['fSize']],\n",
    "                                            stride=[p['sSize'],p['sSize']],\n",
    "                                            padding='SAME',\n",
    "                                           )\n",
    "    if p['maxpool']==True:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "    output = layer\n",
    "    return output, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "def new_fc_layer(input, num_inputs, num_outputs, use_relu=True, dropout=0.05): \n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.dropout(layer, 1-dropout)\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "# Set parameters for CNN layers\n",
    "\n",
    "convolution_params = {\n",
    "    'layer_1a':{'fSize':3, 'fN':16, 'sSize':1, 'activation':'relu', 'channels':1, 'maxpool':True},\n",
    "    'layer_1b':{'fSize':5, 'fN':16, 'sSize':1, 'activation':'relu', 'channels':1, 'maxpool':True},\n",
    "    'layer_1c':{'fSize':7, 'fN':16, 'sSize':1, 'activation':'relu', 'channels':1, 'maxpool':True},\n",
    "    \n",
    "    'layer_2a':{'fSize':3, 'fN':32, 'sSize':1, 'activation':'relu', 'channels':48, 'maxpool':True},\n",
    "    'layer_2b':{'fSize':5, 'fN':32, 'sSize':1, 'activation':'relu', 'channels':48, 'maxpool':True},\n",
    "    'layer_2c':{'fSize':7, 'fN':32, 'sSize':1, 'activation':'relu', 'channels':48, 'maxpool':True},\n",
    "    \n",
    "    'layer_3':{'fSize':5, 'fN':128, 'sSize':1, 'activation':'relu', 'channels':96, 'maxpool':True},\n",
    "    \n",
    "    'layer_4':{'fSize':5, 'fN':256, 'sSize':1, 'activation':'relu', 'channels':128, 'maxpool':True}\n",
    "}\n",
    "\n",
    "fc_params = {\n",
    "    'layer_1':{'nodes':500,'dropout':0.1},\n",
    "    'layer_2':{'nodes':500,'dropout':0.1}\n",
    "}\n",
    "\n",
    "regularization_coefficient = 0.1\n",
    "train_batch_size = 164\n",
    "\n",
    "\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='label')\n",
    "y_true_class = tf.argmax(y_true, axis=1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, 1])\n",
    "\n",
    "p = convolution_params['layer_1a']\n",
    "layer_conv1a, weights_conv1 = new_conv_layer(previous_layer=x_image, param_dic=p)\n",
    "p = convolution_params['layer_1b']\n",
    "layer_conv1b, weights_conv1 = new_conv_layer(previous_layer=x_image, param_dic=p)\n",
    "p = convolution_params['layer_1c']\n",
    "layer_conv1c, weights_conv1 = new_conv_layer(previous_layer=x_image, param_dic=p)\n",
    "layer_conv1 = tf.concat([layer_conv1a,layer_conv1b,layer_conv1c], 3)\n",
    "\n",
    "p = convolution_params['layer_2a']\n",
    "layer_conv2a, weights_conv2 = new_conv_layer(previous_layer=layer_conv1, param_dic=p) \n",
    "p = convolution_params['layer_2b']\n",
    "layer_conv2b, weights_conv2 = new_conv_layer(previous_layer=layer_conv1, param_dic=p) \n",
    "p = convolution_params['layer_2c']\n",
    "layer_conv2c, weights_conv2 = new_conv_layer(previous_layer=layer_conv1, param_dic=p) \n",
    "layer_conv2 = tf.concat([layer_conv2a,layer_conv2b,layer_conv2c], 3)\n",
    "\n",
    "p = convolution_params['layer_3']\n",
    "layer_conv3, weights_conv3 = new_conv_layer(previous_layer=layer_conv2, param_dic=p) \n",
    "\n",
    "p = convolution_params['layer_4']\n",
    "layer_conv4, weights_conv4 = new_conv_layer(previous_layer=layer_conv3, param_dic=p)\n",
    "\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer_conv4)\n",
    "\n",
    "p = fc_params['layer_1']\n",
    "layer_fc1, fc1_weights = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=p['nodes'],\n",
    "                         use_relu=True)\n",
    "\n",
    "p = fc_params['layer_2']\n",
    "layer_fc2, fc2_weights = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=p['nodes'],\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "\n",
    "y_hat = tf.nn.softmax(layer_fc2)\n",
    "y_hat_class = tf.argmax(y_hat, axis=1)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "regularizers = tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc2_weights)\n",
    "cost = tf.reduce_mean(cost + regularization_coefficient * regularizers)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_hat_class, y_true_class)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "train_scores = []\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "    global train_scores\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch, _, _ = data.train.next_batch(train_batch_size)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            train_scores.append(acc)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "# Split the validation-set into smaller batches of this size.\n",
    "validation_batch_size = 256\n",
    "\n",
    "def print_validation_accuracy():\n",
    "\n",
    "    # Number of images in the validation-set.\n",
    "    num_validation = len(data.validation.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_validation, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_validation:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + validation_batch_size, num_validation)\n",
    "\n",
    "        # Get the images from the validation-set between index i and j.\n",
    "        images = data.validation.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.validation.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_hat_class, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the validation-set.\n",
    "    cls_true = data.validation.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the validation-set.\n",
    "    acc = float(correct_sum) / num_validation\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on validation-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  10.4%\n",
      "Optimization Iteration:    101, Training Accuracy:  72.0%\n",
      "Optimization Iteration:    201, Training Accuracy:  76.8%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# ## Performance after 10,000 optimization iterations\n",
    "# \n",
    "# After 10,000 optimization iterations, the model has a classification accuracy on the validation-set of about 99%.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "optimize(num_iterations=501) # We performed 1000 iterations above.\n",
    "\n",
    "print_validation_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1501) # We performed 1000 iterations above.\n",
    "\n",
    "print_validation_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
